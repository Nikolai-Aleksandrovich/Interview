## 进程与线程



### 进程

* 进程（Process） 是计算机中的程序关于某数据集合上的一次运行活动
* 是系 统进行资源分配和调度的基本单位，是操作系统结构的基础。
* 进程是线程的容器。程序是指令、数据及其组织形式的 描述，进程是程序的实体。是计算机中的程序关于某数据集合上的一次运行活 动



### 线程

* 线程（thread） 是操作系统能够进行运算调度的最小单位。
* 它被包含在进程之 中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流
*  一个进程中可以并发多个线程，每条线程并行执行不同的任务

进程：指在系统中正在运行的一个应用程序；程序一旦运行就是进程；进程— —资源分配的最小单位。

 线程：系统分配处理器时间资源的基本单元，或者说进程之内独立执行的一个 单元执行流。线程——程序执行的最小单位。

### 线程的状态

线程状态有一个枚举类：

```
public enum State{
	NEW,RUNNABLE,BLOCKED,WATTING,TIMED_WAITING,TERMINATED
}
```

* new:还未start的线程

* runnable：在虚拟机内已经执行，但是等待CPU分配支援

* blocked：阻塞，等待锁，在等待进入一个同步代码块，或者在调用wait方法后，重入一个同步代码块

* waiting：由于调用以下方法而进入等待状态：Object.wait,Thread.join,LockSupport.park

  进入等待状态，是为了让其他线程完成某个行为

* TimedWaiting：具有特定等待时间的等待，因为调用了这些方法而出现：Thread.sleep,Object,wait,Thread.join,LockSupport.parknanos,LockSupport.parkutils

* terminated，一个结束了的线程，完成了执行

### wait/sleep 的区别

（1）sleep 是 Thread 的静态方法，wait 是 Object 的方法，任何对象实例都 能调用。 

（2）sleep 不会释放锁，它也不需要占用锁。wait 会释放锁，但调用它的前提 是当前线程占有锁(即代码要在 synchronized 中)。 

（3）它们都可以被 interrupted 方法中断。

## 并发与并行  

### 串行模式 

串行表示所有任务都一一按先后顺序进行。

串行是一次只能取得一个任务，并执行这个任务

### 并行模式  

并行意味着可以同时取得多个任务，并同时去执行所取得的这些任务。并行模 式相当于将长长的一条队列，划分成了多条短队列，所以并行缩短了任务队列的长度。并行的效率从代码层次上强依赖于多进程/多线程代码，从硬件角度上 则依赖于多核 CPU。

### 并发  

并发(concurrent)指的是多个程序可以同时运行的现象，更细化的是多进程可 以同时运行或者多指令可以同时运行。

==并发的重点在于它是一种现象==, ==并发描述 的是多进程同时运行的现象==。但实际上，对于单核心 CPU 来说，同一时刻 只能运行一个线程。所以，这里的"同时运行"表示的不是真的同一时刻有多个 线程运行的现象，这是并行的概念，而是提供一种功能让用户看来多个程序同 时运行起来了，但实际上这些程序中的进程不是一直霸占 CPU 的，而是执行一 会停一会。 要解决大并发问题，通常是将大任务分解成多个小任务, 由于操作系统对进程的 调度是随机的，所以切分成多个小任务后，可能会从任一小任务处执行。这可 能会出现一些现象： • 可能出现一个小任务执行了多次，还没开始下个任务的情况。这时一般会采用 队列或类似的数据结构来存放各个小任务的成果 • 可能出现还没准备好第一步就执行第二步的可能。这时，一般采用多路复用或 异步的方式，比如只有准备好产生了事件通知才执行某个任务。 • 可以多进程/多线程的方式并行执行这些小任务。也可以单进程/单线程执行这 些小任务，这时很可能要配合多路复用才能达到较高的效率

## 管程

**管程**(monitor)是保证了同一时刻只有一个进程在管程内活动,即管程内定义的操作在同 一时刻只被一个进程调用(由编译器实现).但是这样并不能保证进程以设计的顺序执行

JVM 中同步是基于进入和退出管程(monitor)对象实现的，每个对象都会有一个管程 (monitor)对象，管程(monitor)会随着 java 对象一同创建和销毁

执行线程首先要持有管程对象，然后才能执行方法，当方法完成之后会释放管程，方 法在执行时候会持有管程，其他线程无法再获取同一个管程

### 用户线程和守护线程  

用户线程:平时用到的普通线程,自定义线程 

守护线程:运行在后台,是一种特殊的线程,比如垃圾回收 当主线程结束后,用户线程还在运行,JVM 存活 如果没有用户线程,都是守护线程,JVM 结束

## Lock 接口 

###  Synchronized 

synchronized 是 Java 中的关键字，是一种同步锁。它修饰的对象有以下几种： 

1. 修饰一个代码块，被修饰的代码块称为同步语句块，其作用的范围是大括号{} 括起来的代码，作用的对象是调用这个代码块的对象；
2. 修饰一个方法，被修饰的方法称为同步方法，其作用的范围是整个方法，作用 的对象是调用这个方法的对象；  虽然可以使用 synchronized 来定义方法，但 synchronized 并不属于方法定 义的一部分，因此，synchronized 关键字不能被继承。如果在父类中的某个方 法使用了 synchronized 关键字，而在子类中覆盖了这个方法，在子类中的这 个方法默认情况下并不是同步的，而必须显式地在子类的这个方法中加上 synchronized 关键字才可以。当然，还可以在子类方法中调用父类中相应的方 法，这样虽然子类中的方法不是同步的，但子类调用了父类的同步方法，因此， 子类的方法也就相当于同步了
3. 修改一个静态的方法，其作用的范围是整个静态方法，作用的对象是这个类的 所有对象； 
4. 修改一个类，其作用的范围是 synchronized 后面括号括起来的部分，作用主 的对象是这个类的所有对象。

如果一个代码块被 synchronized 修饰了，当一个线程获取了对应的锁，并执 行该代码块时，其他线程便只能一直等待，等待获取锁的线程释放锁，而这里 获取锁的线程释放锁只会有两种情况：

 1）获取锁的线程执行完了该代码块，然后线程释放对锁的占有； 

2）线程执行发生异常，此时 JVM 会让线程自动释放锁。 

那么如果这个获取锁的线程由于要等待 IO 或者其他原因（比如调用 sleep 方法）被阻塞了，但是又没有释放锁，其他线程便只能干巴巴地等待，试想一 下，这多么影响程序执行效率。 因此就需要有一种机制可以不让等待的线程一直无期限地等待下去（比如只等 待一定的时间或者能够响应中断），通过 Lock 就可以办到。

### 什么是 Lock

Lock 锁实现提供了比使用同步方法和语句可以获得的更广泛的锁操作。它们允 许更灵活的结构，可能具有非常不同的属性，并且可能支持多个关联的条件对 象。Lock 提供了比 synchronized 更多的功能。 

#### Lock 与的 Synchronized 区别

Lock 不是 Java 语言内置的，synchronized 是 Java 语言的关键字，因此是内 置特性。Lock 是一个类，通过这个类可以实现同步访问；

Lock 和 synchronized 有一点非常大的不同，采用 synchronized 不需要用户 去手动释放锁，当 synchronized 方法或者 synchronized 代码块执行完之后， 系统会自动让线程释放对锁的占用；而 Lock 则必须要用户去手动释放锁，如 果没有主动释放锁，就有可能导致出现死锁现象。

### Lock 接口

```java
public interface Lock {
void lock();
void lockInterruptibly() throws InterruptedException;
boolean tryLock();
boolean tryLock(long time, TimeUnit unit) throws InterruptedException;
void unlock();
Condition newCondition();
}
```

####  lock 

lock()方法是平常使用得最多的一个方法，就是用来获取锁。如果锁已被其他 线程获取，则进行等待。 

采用 Lock，必须主动去释放锁，并且在发生异常时，不会自动释放锁。因此一 般来说，使用 Lock 必须在 try{}catch{}块中进行，并且将释放锁的操作放在 finally 块中进行，以保证锁一定被被释放，防止死锁的发生。通常使用 Lock 来进行同步的话，是以下面这种形式去使用的：

```
Lock lock = new Lock();
lock.lock();
try{
	sout(***)
}catch(Exception e){

}finally{
	lock.unlock();
}
```

#### newCondition

关键字 synchronized 与 wait()/notify()这两个方法一起使用可以实现等待/通 知模式， Lock 锁的 newContition()方法返回 Condition 对象，Condition 类 也可以实现等待/通知模式。

用 notify()通知时，JVM 会随机唤醒某个等待的线程， 使用 Condition 类可以 进行选择性通知， Condition 比较常用的两个方法：

* await()会使当前线程等待,同时会释放锁,当其他线程调用 signal()时,线程会重 新获得锁并继续执行。

* signal()用于唤醒一个等待的线程。

   ==注意：在调用 Condition 的 await()/signal()方法前，也需要线程持有相关 的 Lock 锁，调用 await()后线程会释放这个锁，在 singal()调用后会从当前 Condition 对象的等待队列中，唤醒 一个线程，唤醒的线程尝试获得锁， 一旦 获得锁成功就继续执行。==

### ReentrantLock

ReentrantLock， ReentrantLock 是唯一实现了 Lock 接口的类

###  ReadWriteLock

ReadWriteLock 也是一个接口，在它里面只定义了两个方法：

```
public interface ReadWriteLock{
	Lock readLock();
	Lock writeLock();
}
```

一个用来获取读锁，一个用来获取写锁。也就是说将文件的读写操作分开，分 成 2 个锁来分配给线程，从而使得多个线程可以同时进行读操作。

下面的 ReentrantReadWriteLock 实现了 ReadWriteLock 接口。

 ReentrantReadWriteLock 里面提供了很多丰富的方法，不过最主要的有两个 方法：readLock()和 writeLock()用来获取读锁和写锁。 

* 如果有一个线程已经占用了读锁，则此时其他线程如果要申请写锁，则申请写 锁的线程会一直等待释放读锁。 
* 如果有一个线程已经占用了写锁，则此时其他线程如果申请写锁或者读锁，则 申请的线程会一直等待释放写锁。

### Lock 和 synchronized 有以下几点不同：

*  Lock 是一个接口，而 synchronized 是 Java 中的关键字，synchronized 是内 
* 置的语言实现； 
* synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现 象发生；而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很 可能造成死锁现象，因此使用 Lock 时需要在 finally 块中释放锁； 
* Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用 synchronized 时，等待的线程会一直等待下去，不能够响应中断；
* 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。
* Lock 可以提高多个线程进行读操作的效率。 在性能上来说，如果竞争资源不激烈，两者的性能是差不多的，而当竞争资源 非常激烈时（即有大量线程同时竞争），此时 Lock 的性能要远远优于 synchronized。

## 线程间通信

线程间通信的模型有两种：共享内存和消息传递，以下方式都是基本这两种模 型来实现的。

### 线程间通信

我们来基本一道面试常见的题目来分析 场景---两个线程，一个线程对当前数值加 1，另一个线程对当前数值减 1,要求 用线程间通信

```

```

### 线程间定制化通信

  ==问题: A 线程打印 5 次 A，B 线程打印 10 次 B，C 线程打印 15 次 C,按照 此顺序循环 10 轮==

![image-20210724150729999](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20210724150729999.png)

## 集合的线程安全

### 集合操作 Demo

#### 不安全的集合：

创建100个线程，让他们对一个list进行添加元素操作，会出现并发修改异常java.util.ConcurrentModificationException

## 如何解决list的线程安全问题？

### Vector 

Vector 是矢量队列，它是 JDK1.0 版本添加的类。继承于 AbstractList，实现 了 List, RandomAccess, Cloneable 这些接口。 Vector 继承了 AbstractList， 实现了 List；所以，它是一个队列，支持相关的添加、删除、修改、遍历等功 能。 Vector 实现了 RandmoAccess 接口，即提供了随机访问功能。 RandmoAccess 是 java 中用来被 List 实现，为 List 提供快速访问功能的。在 Vector 中，我们即可以通过元素的序号快速获取元素对象；这就是快速随机访 问。 Vector 实现了 Cloneable 接口，即实现 clone()函数。它能被克隆。

==和 ArrayList 不同，Vector 中的操作是线程安全的。==

###  Collections 

 Collections 提供了方法 synchronizedList 保证 list 是同步线程安全

###  CopyOnWriteArrayList(重点)  

它相当于线程安全的 ArrayList。和 ArrayList 一样，它是个可变数组；但是和 ArrayList 不同的时，它具有以下特性： 

1. 它最适合于具有以下特征的应用程序：List 大小通常保持很小，只读操作远多 于可变操作，需要在遍历期间防止线程间的冲突。 

2. 它是线程安全的。

3. 因为通常需要复制整个基础数组，所以可变操作（add()、set() 和 remove()  等等）的开销很大。 

4. 迭代器支持 hasNext(), next()等不可变操作，但不支持可变 remove()等操作。 

5. 使用迭代器进行遍历的速度很快，并且不会与其他线程发生冲突。在构造迭代 器时，迭代器依赖于不变的数组快照。 

   1. 独占锁效率低：采用读写分离思想解决 

   2. 写线程获取到锁，其他写线程阻塞 

   3. 复制思想：

      当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容 器进行 Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素 之后，再将原容器的引用指向新的容器。 这时候会抛出来一个新的问题，也就是数据不一致的问题。如果写线程还没来 得及写会内存，其他的线程就会读到了脏数据。

       ==这就是 CopyOnWriteArrayList 的思想和原理。就是拷贝一份。==

### ==动态数组与线程安全== 

下面从“动态数组”和“线程安全”两个方面进一步对 CopyOnWriteArrayList 的原理进行说明。 

* “动态数组”机制 

  * 它内部有个“volatile 数组”(array)来保持数据。在“添加/修改/删除”数据 时，都会新建一个数组，并将更新后的数据拷贝到新建的数组中，最后再将该 数组赋值给“volatile 数组”, 这就是它叫做 CopyOnWriteArrayList 的原因 

  * o 由于它在“添加/修改/删除”数据时，都会新建数组，所以涉及到修改数据的 操作，CopyOnWriteArrayList 效率很低；但是单单只是进行遍历查找的话， 效率比较高。 

    

* “线程安全”机制 

  * 通过 volatile 和互斥锁来实现的。 
  * 通过“volatile 数组”来保存数据的。一个线程读取 volatile 数组时，总能看 到其它线程对该 volatile 变量最后的写入；就这样，通过 volatile 提供了“读 取到的数据总是最新的”这个机制的保证。
  * 通过互斥锁来保护数据。在“添加/修改/删除”数据时，会先“获取互斥锁”， 再修改完毕之后，先将数据更新到“volatile 数组”中，然后再“释放互斥 锁”，就达到了保护数据的目的。

1.线程安全与线程不安全集合：集合类型中存在线程安全与线程不安全的两种,常见例如: 

ArrayList ----- Vector 

HashMap -----HashTable 

但是以上都是通过 synchronized 关键字实现,效率较低 

2.Collections 构建的线程安全集合

3.java.util.concurrent 并发包下 CopyOnWriteArrayList CopyOnWriteArraySet 类型,通过动态数组与线程安 全个方面保证线程安全

##  多线程锁  

### 锁的八个问题演示 

一个对象里面如果有多个 synchronized 方法，某一个时刻内，只要一个线程去调用其中的 一个 synchronized 方法了， 其它的线程都只能等待，换句话说，某一个时刻内，只能有唯一一个线程去访问这些 synchronized 方法 

锁的是当前对象 this，被锁定后，其它的线程都不能进入到当前对象的其它的 synchronized 方法 

加个普通方法后发现和同步锁无关 换成两个对象后，不是同一把锁了，情况立刻变化。 

synchronized 实现同步的基础：Java 中的每一个对象都可以作为锁。 具体表现为以下 3 种形式。 

对于普通同步方法，锁是当前实例对象。 

对于静态同步方法，锁是当前类的 Class 对象。 

对于同步方法块，锁是 Synchonized 括号里配置的对象 

当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。 

也就是说如果一个实例对象的非静态同步方法获取锁后，该实例对象的其他非静态同步方 法必须等待获取锁的方法释放锁后才能获取锁， 可是别的实例对象的非静态同步方法因为跟该实例对象的非静态同步方法用的是不同的锁， 所以毋须等待该实例对象已获取锁的非静态同步方法释放锁就可以获取他们自己的锁。 

所有的静态同步方法用的也是同一把锁——类对象本身，这两把锁是两个不同的对象，所 以静态同步方法与非静态同步方法之间是不会有竞态条件的。 

但是一旦一个静态同步方法获取锁后，其他的静态同步方法都必须等待该方法释放锁后才 能获取锁，而不管是同一个实例对象的静态同步方法之间，还是不同的实例对象的静态同 步方法之间，只要它们同一个类的实例对象！

## Callable&Future 接口 

### Callable 接口

目前我们学习了有两种创建线程的方法-一种是通过创建 Thread 类，另一种是 通过使用 Runnable 创建线程。但是，Runnable 缺少的一项功能是，当线程 终止时（即 run（）完成时），我们无法使线程返回结果。为了支持此功能， Java 中提供了 Callable 接口。

### Callable 接口的特点如下(重点)

* 为了实现 Runnable，需要实现不返回任何内容的 run（）方法，而对于 Callable，需要实现在完成时返回结果的 call（）方法。 

* call（）方法可以引发异常，而 run（）则不能。

* 为实现 Callable 而必须重写 call 方法

* 不能直接替换 runnable,因为 Thread 类的构造方法根本没有 Callable

### Future 接口

当 call（）方法完成时，结果必须存储在主线程已知的对象中，以便主线程可 以知道该线程返回的结果。为此，可以使用 Future 对象。

将 Future 视为保存结果的对象–它可能暂时不保存结果，但将来会保存（一旦 Callable 返回）。Future 基本上是主线程可以跟踪进度以及其他线程的结果的 一种方式。要实现此接口，必须重写 5 种方法，这里列出了重要的方法,如下: 

* public boolean cancel（boolean mayInterrupt）：用于停止任务。 ==如果尚未启动，它将停止任务。如果已启动，则仅在 mayInterrupt 为 true 时才会中断任务。
* == • public Object get（）抛出 InterruptedException，ExecutionException： 用于获取任务的结果。 ==如果任务完成，它将立即返回结果，否则将等待任务完成，然后返回结果。 
* == • public boolean isDone（）：如果任务完成，则返回 true，否则返回 false 可以看到 Callable 和 Future 做两件事-Callable 与 Runnable 类似，因为它封 装了要在另一个线程上运行的任务，而 Future 用于存储从另一个线程获得的结 果。实际上，future 也可以与 Runnable 一起使用。 要创建线程，需要 Runnable。为了获得结果，需要 future。

## FutureTask 

Java 库具有具体的 FutureTask 类型，该类型实现 Runnable 和 Future，并方 便地将两种功能组合在一起。 可以通过为其构造函数提供 Callable 来创建 FutureTask。然后，将 FutureTask 对象提供给 Thread 的构造函数以创建 Thread 对象。

因此，间接地使用 Callable 创建线程。 

#### 核心原理:(重点)

 在主线程中需要执行比较耗时的操作时，但又不想阻塞主线程时，可以把这些 作业交给 Future 对象在后台完成 

• 当主线程将来需要时，就可以通过 Future 对象获得后台作业的计算结果或者执 行状态

• 一般 FutureTask 多用于耗时的计算，主线程可以在完成自己的任务后，再去 获取结果。 

• 仅在计算完成时才能检索结果；如果计算尚未完成，则阻塞 get 方法 • 一旦计算完成，就不能再重新开始或取消计算 

• get 方法而获取结果只有在计算完成时获取，否则会一直阻塞直到任务转入完 成状态，然后会返回结果或者抛出异常

• get 只计算一次,因此 get 方法放到最后



在主线程中需要执行比较耗时的操作时，但又不想阻塞主线程时，可以把这些 作业交给 Future 对象在后台完成, 当主线程将来需要时，就可以通过 Future 对象获得后台作业的计算结果或者执行状态

• 一般 FutureTask 多用于耗时的计算，主线程可以在完成自己的任务后，再去 获取结果 

• 仅在计算完成时才能检索结果；如果计算尚未完成，则阻塞 get 方法。一旦计 算完成，就不能再重新开始或取消计算。get 方法而获取结果只有在计算完成 时获取，否则会一直阻塞直到任务转入完成状态，然后会返回结果或者抛出异 常。 

• 只计算一次

##  JUC 三大辅助类

JUC 中提供了三种常用的辅助类，通过这些辅助类可以很好的解决线程数量过 多时 Lock 锁的频繁操作。

这三种辅助类为：

 • CountDownLatch: 减少计数

 • CyclicBarrier: 循环栅栏

 • Semaphore: 信号灯

### 减少计数 CountDownLatch 

CountDownLatch 类可以设置一个计数器，然后通过 countDown 方法来进行 减 1 的操作，使用 await 方法等待计数器不大于 0，然后继续执行 await 方法 之后的语句。

 • CountDownLatch 主要有两个方法，当一个或多个线程调用 await 方法时，这 些线程会阻塞 

• 其它线程调用 countDown 方法会将计数器减 1(调用 countDown 方法的线程 不会阻塞) 

• 当计数器的值变为 0 时，因 await 方法阻塞的线程会被唤醒，继续执行

### 循环栅栏 CyclicBarrier  CyclicBarrier

看英文单词可以看出大概就是循环阻塞的意思，在使用中 CyclicBarrier 的构造方法第一个参数是目标障碍数，每次执行 CyclicBarrier 一 次障碍数会加一，如果达到了目标障碍数，才会执行 cyclicBarrier.await()之后 的语句。可以将 CyclicBarrier 理解为加 1 操作

### 信号灯 Semaphore

Semaphore 的构造方法中传入的第一个参数是最大信号量（可以看成最大线 程池），每个信号量初始化为一个最多只能分发一个许可证。使用 acquire 方 法获得许可证，release 方法释放许可

## 读写锁

### 读写锁介绍

现实中有这样一种场景：对共享资源有读和写的操作，且写操作没有读操作那 么频繁。在没有写操作的时候，多个线程同时读一个资源没有任何问题，所以 应该允许多个线程同时读取共享资源；但是如果一个线程想去写这些共享资源， 就不应该允许其他线程对该资源进行读和写的操作了。 

针对这种场景，JAVA 的并发包提供了读写锁 ReentrantReadWriteLock， 它表示两个锁，一个是读操作相关的锁，称为共享锁；一个是写相关的锁，称 为排他锁

* 线程进入读锁的前提条件： 
  * 没有其他线程的写锁 
  * 没有写请求, 或者==有写请求，但调用线程和持有锁的线程是同一个(可重入 锁)。== 
  
* 线程进入写锁的前提条件： 

  * 没有其他线程的读锁

  * 没有其他线程的写锁

而读写锁有以下三个重要的特性： 

（1）公平选择性：支持非公平（默认）和公平的锁获取方式，吞吐量还是非公 平优于公平。 

（2）重进入：读锁和写锁都支持线程重进入。 

（3）锁降级：遵循获取写锁、获取读锁再释放写锁的次序，写锁能够降级成为 读锁

可以看到，ReentrantReadWriteLock 实现了 ReadWriteLock 接口， ReadWriteLock 接口定义了获取读锁和写锁的规范，具体需要实现类去实现； 同时其还实现了 Serializable 接口，表示可以进行序列化，在源代码中可以看 到 ReentrantReadWriteLock 实现了自己的序列化逻辑

## 小结

• 在线程持有读锁的情况下，该线程不能取得写锁(因为获取写锁的时候，如果发 现当前的读锁被占用，就马上获取失败，不管读锁是不是被当前线程持有)。

 • 在线程持有写锁的情况下，该线程可以继续获取读锁（获取读锁时如果发现写 锁被占用，只有写锁没有被当前线程占用的情况才会获取失败）。 

原因: 当线程获取读锁的时候，可能有其他线程同时也在持有读锁，因此不能把 获取读锁的线程“升级”为写锁；

而对于获得写锁的线程，它一定独占了读写 锁，因此可以继续让它获取读锁，当它同时获取了写锁和读锁后，还可以先释 放写锁继续持有读锁，这样一个写锁就“降级”为了读锁。

##  阻塞队列

BlockingQueue 

当队列是空的，从队列中获取元素的操作将会被阻塞 

当队列是满的，从队列中添加元素的操作将会被阻塞 

试图从空的队列中获取元素的线程将会被阻塞，直到其他线程往空的队列插入新的元素 

试图向已满的队列中添加新元素的线程将会被阻塞，直到其他线程从队列中移除一个或多 个元素或者完全清空，使队列变得空闲起来并后续新增 

常用的队列主要有以下两种： 

• 先进先出（FIFO）：先插入的队列的元素也最先出队列，类似于排队的功能。 从某种程度上来说这种队列也体现了一种公平性

 • 后进先出（LIFO）：后插入队列的元素最先出队列，这种队列优先处理最近发 生的事件(栈) 

在多线程领域：所谓阻塞，在某些情况下会挂起线程（即阻塞），一旦条件满足，被挂起 的线程又会自动被唤起 为什么需要 BlockingQueue 好处是我们不需要关心什么时候需要阻塞线程，什么时候需要唤醒线程，因为这一切 BlockingQueue 都给你一手包办了 在 concurrent 包发布以前，在多线程环境下，我们每个程序员都必须去自己控制这些细 节，尤其还要兼顾效率和线程安全，而这会给我们的程序带来不小的复杂度。

多线程环境中，通过队列可以很容易实现数据共享，比如经典的“生产者”和 “消费者”模型中，通过队列可以很便利地实现两者之间的数据共享。假设我 们有若干生产者线程，另外又有若干个消费者线程。如果生产者线程需要把准 备好的数据共享给消费者线程，利用队列的方式来传递数据，就可以很方便地 解决他们之间的数据共享问题。但如果生产者和消费者在某个时间段内，万一 发生数据处理速度不匹配的情况呢？理想情况下，如果生产者产出数据的速度 大于消费者消费的速度，并且当生产出来的数据累积到一定程度的时候，那么 生产者必须暂停等待一下（阻塞生产者线程），以便等待消费者线程把累积的 数据处理完毕，反之亦然。

 • 当队列中没有数据的情况下，消费者端的所有线程都会被自动阻塞（挂起）， 直到有数据放入队列 

• 当队列中填满数据的情况下，生产者端的所有线程都会被自动阻塞（挂起）， 直到队列中有空的位置，线程被自动唤醒

###  BlockingQueue 核心方法

#### 放入数据

• offer(anObject):表示如果可能的话,将 anObject 加到 BlockingQueue 里,即 如果 BlockingQueue 可以容纳,则返回 true,否则返回 false.（本方法不阻塞当 前执行方法的线程） 

• offer(E o, long timeout, TimeUnit unit)：可以设定等待的时间，如果在指定 的时间内，还不能往队列中加入 BlockingQueue，则返回失败

• put(anObject):把 anObject 加到 BlockingQueue 里,如果 BlockQueue 没有 空间,则调用此方法的线程被阻断直到 BlockingQueue 里面有空间再继续.

#### 获取数据 

• poll(time): 取走 BlockingQueue 里排在首位的对象,若不能立即取出,则可以等 time 参数规定的时间,取不到时返回 null 

• poll(long timeout, TimeUnit unit)：从 BlockingQueue 取出一个队首的对象， 如果在指定时间内，队列一旦有数据可取，则立即返回队列中的数据。否则知 道时间超时还没有数据可取，返回失败。 

• take(): 取走 BlockingQueue 里排在首位的对象,若 BlockingQueue 为空,阻断 进入等待状态直到 BlockingQueue 有新的数据被加入;

• drainTo(): 一次性从 BlockingQueue 获取所有可用的数据对象（还可以指定 获取数据的个数），通过该方法，可以提升获取数据效率；不需要多次分批加 锁或释放锁

###  常见的 BlockingQueue

####  ArrayBlockingQueue(常用)

基于数组的阻塞队列实现，在 ArrayBlockingQueue 内部，维护了一个定长数 组，以便缓存队列中的数据对象，这是一个常用的阻塞队列，除了一个定长数 组外，ArrayBlockingQueue 内部还保存着两个整形变量，分别标识着队列的 头部和尾部在数组中的位置。

 ArrayBlockingQueue 在生产者放入数据和消费者获取数据，都是共用同一个 锁对象，由此也意味着两者无法真正并行运行，这点尤其不同于 LinkedBlockingQueue；按照实现原理来分析，ArrayBlockingQueue 完全可 以采用分离锁，从而实现生产者和消费者操作的完全并行运行。Doug Lea 之 所以没这样去做，也许是因为 ArrayBlockingQueue 的数据写入和获取操作已 经足够轻巧，以至于引入独立的锁机制，除了给代码带来额外的复杂性外，其 在性能上完全占不到任何便宜。 ArrayBlockingQueue 和 LinkedBlockingQueue 间还有一个明显的不同之处在于，前者在插入或删除 元素时不会产生或销毁任何额外的对象实例，而后者则会生成一个额外的 Node 对象。这在长时间内需要高效并发地处理大批量数据的系统中，其对于 GC 的影响还是存在一定的区别。而在创建 ArrayBlockingQueue 时，我们还 可以控制对象的内部锁是否采用公平锁，默认采用非公平锁。

#### LinkedBlockingQueue(常用)

基于链表的阻塞队列，同 ArrayListBlockingQueue 类似，其内部也维持着一 个数据缓冲队列（该队列由一个链表构成），当生产者往队列中放入一个数据 时，队列会从生产者手中获取数据，并缓存在队列内部，而生产者立即返回； 只有当队列缓冲区达到最大值缓存容量时（LinkedBlockingQueue 可以通过 构造函数指定该值），才会阻塞生产者队列，直到消费者从队列中消费掉一份数据，生产者线程会被唤醒，反之对于消费者这端的处理也基于同样的原理。 而 LinkedBlockingQueue 之所以能够高效的处理并发数据，还因为其对于生 产者端和消费者端分别采用了独立的锁来控制数据同步，这也意味着在高并发 的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列 的并发性能。

 ArrayBlockingQueue 和 LinkedBlockingQueue 是两个最普通也是最常用 的阻塞队列，一般情况下，在处理多线程间的生产者消费者问题，使用这两个 类足以。 

==一句话总结: 由链表结构组成的有界（但大小默认值为 integer.MAX_VALUE）阻塞队列。==

### DelayQueue 

DelayQueue 中的元素只有当其指定的延迟时间到了，才能够从队列中获取到 该元素。DelayQueue 是一个没有大小限制的队列，因此往队列中插入数据的 操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻 塞。 

==一句话总结: 使用优先级队列实现的延迟无界阻塞队列。==

### PriorityBlockingQueue

基于优先级的阻塞队列（优先级的判断通过构造函数传入的 Compator 对象来 决定），但需要注意的是 PriorityBlockingQueue 并不会阻塞数据生产者，而 只会在没有可消费的数据时，阻塞数据的消费者。 因此使用的时候要特别注意，生产者生产数据的速度绝对不能快于消费者消费 数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。 在实现 PriorityBlockingQueue 时，内部控制线程同步的锁采用的是公平锁。 

==一句话总结: 支持优先级排序的无界阻塞队列。==

###  SynchronousQueue

一种无缓冲的等待队列，类似于无中介的直接交易，有点像原始社会中的生产 者和消费者，生产者拿着产品去集市销售给产品的最终消费者，而消费者必须 亲自去集市找到所要商品的直接生产者，如果一方没有找到合适的目标，那么 对不起，大家都在集市等待。相对于有缓冲的 BlockingQueue 来说，少了一 个中间经销商的环节（缓冲区），如果有经销商，生产者直接把产品批发给经 销商，而无需在意经销商最终会将这些产品卖给那些消费者，由于经销商可以 库存一部分商品，因此相对于直接交易模式，总体来说采用中间经销商的模式 会吞吐量高一些（可以批量买卖）；但另一方面，又因为经销商的引入，使得 产品从生产者到消费者中间增加了额外的交易环节，单个产品的及时响应性能 可能会降低。

 声明一个 SynchronousQueue 有两种不同的方式，它们之间有着不太一样的 行为

公平模式和非公平模式的区别: 

• 公平模式：SynchronousQueue 会采用公平锁，并配合一个 FIFO 队列来阻塞 多余的生产者和消费者，从而体系整体的公平策略； 

• 非公平模式（SynchronousQueue 默认）：SynchronousQueue 采用非公平 锁，同时配合一个 LIFO 队列来管理多余的生产者和消费者，而后一种模式， 如果生产者和消费者的处理速度有差距，则很容易出现饥渴的情况，即可能有 某些生产者或者是消费者的数据永远都得不到处理。 

==一句话总结: 不存储元素的阻塞队列，也即单个元素的队列。==

#### LinkedTransferQueue 

LinkedTransferQueue 是一个由链表结构组成的无界阻塞 TransferQueue 队 列。相对于其他阻塞队列，LinkedTransferQueue 多了 tryTransfer 和 transfer 方法。 LinkedTransferQueue 采用一种预占模式。意思就是消费者线程取元素时，如 果队列不为空，则直接取走数据，若队列为空，那就生成一个节点（节点元素 为 null）入队，然后消费者线程被等待在这个节点上，后面生产者线程入队时 发现有一个元素为 null 的节点，生产者线程就不入队了，直接就将元素填充到该节点，并唤醒该节点等待的线程，被唤醒的消费者线程取走元素，从调用的 方法返回。 ==一句话总结: 由链表组成的无界阻塞队列。==

#### LinkedBlockingDeque 

LinkedBlockingDeque 是一个由链表结构组成的双向阻塞队列，即可以从队 列的两端插入和移除元素。 对于一些指定的操作，在插入或者获取队列元素时如果队列状态不允许该操作 可能会阻塞住该线程直到队列状态变更为允许操作，这里的阻塞一般有两种情 况 

• 插入元素时: 如果当前队列已满将会进入阻塞状态，一直等到队列有空的位置时 再讲该元素插入，该操作可以通过设置超时参数，超时后返回 false 表示操作 失败，也可以不设置超时参数一直阻塞，中断后抛出 InterruptedException 异 常 

• 读取元素时: 如果当前队列为空会阻塞住直到队列不为空然后返回元素，同样可 以通过设置超时参数 ==一句话总结: 由链表组成的双向阻塞队列==

### 阻塞

在多线程领域：所谓阻塞，在某些情况下会挂起线程（即阻塞），一旦条件 满足，被挂起的线程又会自动被唤起

## ThreadPool 线程池

线程池（英语：thread pool）：一种线程使用模式。线程过多会带来调度开销， 进而影响缓存局部性和整体性能。而线程池维护着多个线程，等待着监督管理 者分配可并发执行的任务。这避免了在处理短时间任务时创建与销毁线程的代 价。线程池不仅能够保证内核的充分利用，还能防止过分调度。

 线程池的优势： 线程池做的工作只要是控制运行的线程数量，处理过程中将任 务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量， 超出数量的线程排队等候，等其他线程执行完毕，再从队列中取出任务来执行。 

它的主要特点为：

 • 降低资源消耗: 通过重复利用已创建的线程降低线程创建和销毁造成的销耗。

 • 提高响应速度: 当任务到达时，任务可以不需要等待线程创建就能立即执行。

 • 提高线程的可管理性: 线程是稀缺资源，如果无限制的创建，不仅会销耗系统资 源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

 • Java 中的线程池是通过 Executor 框架实现的，该框架中用到了 Executor，Executors， ExecutorService，ThreadPoolExecutor 这几个类

![image-20210724212610639](C:/Users/lenovo/AppData/Roaming/Typora/typora-user-images/image-20210724212610639.png)

### 常用参数(重点) 

• corePoolSize 线程池的核心线程数 

• maximumPoolSize 能容纳的最大线程数 

• keepAliveTime 空闲线程存活时间

 • unit 存活的时间单位 

• workQueue 存放提交但未执行任务的队列 

• threadFactory 创建线程的工厂类 

• handler 等待队列满后的拒绝策略

### 拒绝策略(重点）

CallerRunsPolicy: 当触发拒绝策略，只要线程池没有关闭的话，则使用调用 线程直接运行任务。一般并发比较小，性能要求不高，不允许失败。但是，由 于调用者自己运行任务，如果任务提交速度过快，可能导致程序阻塞，性能效 率上必然的损失较大 

AbortPolicy: 丢弃任务，并抛出拒绝执行 RejectedExecutionException 异常 信息。线程池默认的拒绝策略。必须处理好抛出的异常，否则会打断当前的执 行流程，影响后续的任务执行。 

DiscardPolicy: 直接丢弃，其他啥都没有 

DiscardOldestPolicy: 当触发拒绝策略，只要线程池没有关闭的话，丢弃阻塞 队列 workQueue 中最老的一个任务，并将新任务加入

## 线程池的种类与创建

###  newCachedThreadPool(常用)

作用：创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空 闲线程，若无可回收，则新建线程. 

场景: 适用于创建一个可无限扩大的线程池，服务器负载压力较轻，执行时间较 短，任务多的场景

特点: 

 • 线程池中数量没有固定，可达到最大值（Interger. MAX_VALUE） • 线程池中的线程可进行缓存重复利用和回收（回收默认时间为 1 分钟）

 • 当线程池中，没有可用线程，会重新创建一个线程 创建方式

```
public static ExecutorService newCachedThreadPool(){
        return new ThreadPoolExecutor(
                0,
                Integer.MAX_VALUE,
                60L,
                TimeUnit.SECONDS,
                new SynchronousQueue<>(),
                Executors.defaultThreadFactory(),
                new ThreadPoolExecutor.AbortPolicy());
    }
```

### newFixedThreadPool(常用)

创建一个可重用固定线程数的线程池，以共享的无界队列方式来运行这 些线程。

在任意点，在大多数线程会处于处理任务的活动状态。如果在所有线 程处于活动状态时提交附加任务，则在有可用线程之前，附加任务将在队列中 等待。如果在关闭前的执行期间由于失败而导致任何线程终止，那么一个新线 程将代替它执行后续的任务（如果需要）。在某个线程被显式地关闭之前，池 中的线程将一直存在。

场景: 适用于可以预测线程数量的业务中，或者服务器负载较重，对线程数有严 格限制的场景

特征： 

• 线程池中的线程处于一定的量，可以很好的控制线程的并发量 

• 线程可以重复被使用，在显示关闭之前，都将一直存在 

• 超出一定量的线程被提交时候需在队列中等待

```
 public static ExecutorService newFixedThreadPool(){
        return new ThreadPoolExecutor(
                10,
                20,
                60L,
                TimeUnit.SECONDS,
                new LinkedBlockingDeque<>(),
                Executors.defaultThreadFactory(),
                new ThreadPoolExecutor.AbortPolicy());
    }
```

### newSingleThreadExecutor(常用)

作用：创建一个使用单个 worker 线程的 Executor，以无界队列方式来运行该 线程。（注意，如果因为在关闭前的执行期间出现失败而终止了此单个线程， 那么如果需要，一个新线程将代替它执行后续的任务）。

可保证顺序地执行各 个任务，并且在任意给定的时间不会有多个线程是活动的。与其他等效的 newFixedThreadPool 不同，可保证无需重新配置此方法所返回的执行程序即 可使用其他的线程。 特征： 线程池中最多执行 1 个线程，之后提交的线程活动将会排在队列中以此 执行

适用于需要保证顺序执行各个任务，并且在任意时间点，不会同时有多个 线程的场景

###  newScheduleThreadPool(了解)

作用: 线程池支持定时以及周期性执行任务，创建一个 corePoolSize 为传入参 数，最大线程数为整形的最大数的线程池** 

特征: 

（1）线程池中具有指定数量的线程，即便是空线程也将保留 

（2）可定时或者 延迟执行线程活动

### newWorkStealingPool

jdk1.8 提供的线程池，底层使用的是 ForkJoinPool 实现，创建一个拥有多个 任务队列的线程池，可以减少连接数，创建当前可用 cpu 核数的线程来并行执 行任务

```
public static ExecutorService newWorkStealingPool(int parallelism){
        return new ForkJoinPool(parallelism,ForkJoinPool.defaultForkJoinWorkerThreadFactory,null,true);
    }
```

