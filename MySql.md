## 死锁

* 两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，导致恶性循环
* 多个事务以不同顺序锁定资源，或者多个事务同时锁定同一资源时，会导致死锁

解决方法：

* 查询时间达到锁规定的超时时间，就会放弃锁请求
* innodb能检测死锁的循环依赖，直接放弃锁请求，将持有最少行级排他锁的事务进行回滚

## 事务日志（预写式日志）

* 发生修改时，首先把修改写到拷贝到内存的数据副本中
* 将修改行为写入磁盘的事务日志中。使用顺序IO，不需要多地移动磁头
* 再合适的时间，将内存中的修改持久化到数据文件中

## MVCC

* 是行锁的上位替代，避免加锁操作，开销更低，是非阻塞的读，写操作只锁定单行
* 通过保留数据在某个时间点的快照实现，分为乐观并发控制、悲观并发控制
* InnoDB的MVCC在每一行最后放置两列，保存创建行的时间和行的过期时间，存储的为系统版本号，每有一个事务操作，那么版本号就增加，事务开始时的版本号就是当时系统版本号，用来与每行数据的版本号相对比，
  * Select：只会查询早于当前事务版本的数据行（如果创建版本号大于事务版本号，则对当前事务是不可见的）；行的删除版本要么未定义，要么大于当前事务版本号（确保事务在执行过程中，行未删除）
  * Insert：版本号为当前系统版本号
  * Delete：当前系统版本号为删除版本
  * Update：插入一条新记录，当前版本号为行版本号，当前版本号设置为原数据行的删除版本号
* 只在可重复读和读已提交两种隔离级别下，这样避免幻读。因为读未提交总是读最新的数据行，而不是根据版本号读取

## InnoDB

* 采用MVCC支持高并发，默认隔离级别是可重复读，采用间隙锁防止幻读出现，不光会锁当前行，会使索引中的间隙进行锁定
* 使用聚簇索引建立表，主键查询有很高性能，但二级索引必须包含主键列，如果主键很大，那么其他索引都会很大。因为存储数据时独立的，方便不同平台移植
* 优化：
  * 可预测性预读
  * 自适应哈希索引
  * 插入缓冲区

## MyISAM

* 不支持事务和行锁，崩溃后无法恢复
* 读取和插入使用共享和排他锁，但使用并发插入：插入时可以读取
* 数据压缩后很省空间


# 数据类型

## 整数类型：

TINYINT，SMALLINT，MEDIUMINT，INT，BIGINT，分别用8，16，24，32，64位存储空间

## 实数类型：

* DECIMAL支持精确计算，精确存储，而且可以存储比BIGINT更大的整数，允许最多65个数字，只是一种存储格式，实际计算时，会转成DOUBLE，FLOAT使用4个字节，DECIMAL使用8个字节
* 可以使用BIGINT存储DECIMAL，乘以一个数字就可以

## 字符串：

### VARCHAR：

* 比定长类型更省空间，仅使用必要的空间，需要一个多余的空间来存储长度，对于255以内只需要一个字节，对于255以外，需要2个字节
* 如果一个长度可变的行更新，此时页内已经没有空间存储，MyisAM会把这行分开存储，InnoDB会进行分裂页处理
* 字符串列的最大长度若大于平均长度，更新很少，则可以使用Varchar

### char：

* 定长，适合经常变更的，长度固定的，因为不会产生碎片

### 思考：

使用varchar100和char4存储‘hell’一样吗？

不一样，Mysql会存储固定大小的内存块保存内存值

## BLOB和TEXT

*  作为对象存储，如果过大，则当前行存储一个1-4字节的指针，然后在外部区域存储实际的值
* BLOB是二进制数据，TEXT是字符集和排序规则
* 排序：只对前面部分字符串进行排序，无法为全部字符集建立索引
* 使用枚举替代字符串集合，但枚举很难改变

## DATETIME和TIMESTAMP

DATETIME：存储到秒，8个字节

TIMESTAMP：1970年的秒数，依赖时区，如果插入没有设置时间，则插入当前时间，默认是NOT NULL，

## MySQL设计schema的陷阱

### 过多的列：

存储引擎API工作时，需要从存储引擎层和服务器层之间用行缓冲格式拷贝数据，在服务器层将缓冲内容解码为列，再将该解码过的列转为行数据结构的操作代价很高，如果是MyISAM的定长行结构，就不需要转换为行数据结构，如果是变长行结构或者InnoDB，那么转换的代价依赖于列的数量

### 太多的表关联：

单个查询应该尽量少关联表

### 避免过多使用枚举

## 范式和反范式

1.第一范式(1NF):列不可再分 1.每一列属性都是不可再分的属性值,确保每一列的原子性 2.两列的属性相近或相似或一样,尽量合并属性一样的列,确保不产生冗余数据

2.第二范式（2NF）属性完全依赖于主键
第二范式（2NF）要求数据库表中的每个实例或行必须可以被惟一地区分。为实现区分通常需要为表加上一个列，以存储各个实例的惟一标识。这个惟一属性列被称为主键

3.第三范式（3NF）属性不依赖于其它非主属性    属性直接依赖于主键

数据不能存在传递关系，即每个属性都跟主键有直接关系而不是间接关系。像：a-->b-->c  属性之间含有这样的关系，是不符合第三范式的。

### 范式的优点：

* 更新操作更快

* 几乎没有重复数据

* 表更小

* 更少需要group by或者distinct

* 全表几乎是顺序IO，而不是随机IO 

  

### 计数器表：

* 多行同时写入，而不是单行互斥写锁，统计时相加即可
* 设置周期执行的任务，将其他槽的任务汇总到第一条记录中
* 更快的读，更慢的写：
  * 额外索引，冗余列，创建汇总表和缓冲表会加快读操作，但是降低写操作

## 高代价的ALTER TABLE

一般ALTERTABLE操作是先创建一个新表，然后将旧表的数据导入新表，然后删除旧表，会特别慢，所以尽量修改.frm文件

ALTERTABLE操作会导致服务器宕机，可以现在另一台不提供的服务器上进行，再切换。也可以使用影子拷贝

## 修改.frm文件

* 移除AI属性

* 增删改ENUM和SET常量

  方法：

  * 创建一张同样的孔表，修改进行
  * 执行Flust table with read lock，关闭任何使用中的表
  * 交换frm文件
  * Unlock table

## MyISAM索引

新增数据进行索引：可以防止碎片索引，也可以利用排序构建索引

* 关闭索引
* 加入数据
* 开启索引

但对唯一索引无效，无法关闭唯一索引，依赖InnoDB快速创建索引功能，先删除所有非唯一索引，增加新的列，在创建删除的索引。

也可以用另一种方法：

* 用当前表结构创建一个空表，不包含新索引

* 载入数据，得到.MYD

* 按照结构创建一个空表，包含索引，得到.frm .MYI

* 获取读锁刷新表

* 将第二个表的.frm和.MYI改成第一个的

* 释放读锁

* RePAIR Table进行重建索引，通过排序构建索引

  这个操作会快很多

# 索引

索引工作在存储引擎层，所以不同的存储引擎的索引存储方式不一样

* InnoDB使用B-树

  * 每一个叶子到根的距离相同，值按顺序存储
  * 从根节点向下寻找，每个节点存储指向子节点的指针，通过比较结点的值和要查找的值找到合适的指针
  * 叶子节点指向被索引的数据，叶子节点之间用链表相连
  * B-树适合：全键值、键值范围、键前缀查找
    * 全值匹配：和索引中所有列进行匹配
    * 最左前缀：只使用索引的第一列
    * 匹配最左前缀：某一列值的开头部分
    * 匹配范围值：
    * 精确某一列，并范围匹配另一列：
    * 只访问索引的查询
    * 支持ORDERBY操作
  * 不适合：
    * 违反最左匹配原则
    * 跳过一个索引
    * 如果有一个模糊查询，那么该索引右边的都不走索引

  哈希索引：

  * 只包含哈希值和指针，不包含数据
  * 无法应用于排序
  * 不支持部分索引列匹配查找
  * 只支持等值比较查询，不支持范围查询

  InnoDB的自适应哈希索引：

  * 当某些索引值被使用的非常频繁，就会在内存中独立于B-树构建哈希索引

为什么要用索引：

* 加速查询，减少服务器扫描的区域
* 避免排序和临时表
* 避免随机IO，使用顺序IO

索引的缺点：

* 索引并不是最好的，只有当索引带来的查询加速重要于他带来的额外工作，才可以用
* 对超大表数量较多，可以在索引的基础上建立元数据信息表，指明某用户的信息存在某表

### 高性能索引的诀窍：

* 索引列不能是表达式的参数，也不能是函数的一部分
* 前缀索引和索引选择性：对很长的字符串，使用前缀索引，只对前缀某长度建立索引
* 多列索引：出现索引合并时，多个单列索引分开查询，将得到的结果合并，这说明索引建立的很糟糕，会消耗大部分缓存和cpu在合并操作上，应该调整为多列索引或者关闭合并，直接用模糊查询
* 选择合适的索引列顺序：
  * 将选择性最高的放在最左边，尽量避免随机IO

### 聚簇索引：

* 是一种数据存储方式，数据存放在叶子节点，因为无法把数据放在别的地方，所以一个表只有一个聚簇索引
* InnoDB用主键聚簇索引，如果没有主键，就用一个唯一的非空索引代替，如果没有，就隐式指定
* 优点：
  * 查询非常块
  * 利于数据聚集
  * 方便覆盖索引，直接使用页节点的主键值
* 缺点：
  * 比不上全内存查询
  * 严重影响非顺序的插入速度
  * 更新索引的代价很高
  * 插入新行或者主键更新导致要移动行的时候，可能出现页分裂，当行的主键值要求必须将这个行插入到一个已满的行上，那么就需要将该页分为连个页面存储，导致占用更多磁盘空间
  * 当出现页分裂或数据稀疏时，导致全表扫面变慢
  * 二级索引会变大，因为二级索引的叶子节点包含了引用行的主键列
  * 二级索引需要两次索引查找，二级索引存储的是指向行的主键值，第一次得到主键值，第二次得到数据
  * InnoDB的自适应哈希索引可以减少两次查找

#### InnoDB按主键顺序插入行

因为主键是顺序的，所以把每一条新纪录插入到以前记录的后边，达到页的最大填充因子，就开辟新的页，如果不是顺序的，就要为新行寻找任何可能的位置

* 写入的目标页可能已经刷到磁盘上，缓存中没有，也有可能没加载到缓存中，所以不得不先读到缓存中，导致大量随机IO
* 可能会频繁的触发页分裂，移动大量数据，一次插入要修改三个页
* 频繁的页分裂会导致数据碎片化

总结：应该尽量按主键顺序插入数据，尽可能使用单调增加的聚簇键插入新行

缺点：主键顺序插入会在高并发情况下使用排他锁，性能较差

### 覆盖查询

覆盖查询指：一个索引包含了要查询字段的值

* 减少数据读取量和IO，因为查询索引可以直接放到内存中，减少数据拷贝
* 减少IO，索引是按照列值顺序存储的，对于高并发范围查询快很多
* MyISAM在内存中放索引，磁盘查询缓存在操作系统，如果避免查询磁盘，那避免性能问题
* 对InnoDB，如果第一次使用二级索引就可以查到数据，那么就不需要第二次查询

### 使用索引扫描进行排序

* mysql排序有两种方法：普通的排序和索引顺序扫描排序
* 索引顺序扫描排序很快，但是如果索引不能覆盖所查询的全部列，那就不得不每次都进行两次查询，那将会很慢，这就是随机IO，这样会比顺序的扫描全表还慢
* 设计索引尽可能既满足排序，也可以用于查找行
* 只有当索引列顺序和ORDER BY顺序完全一样，所有列的排序方向都一样，才可以使用索引进行排序，需要满足最左前缀的要求，如果要违反，那要确保第一个列为常量

扫描索引是非常快的，

### 索引前缀压缩

MyISAM压缩每个索引块：先保存索引块中的第一个值，将其他值和第一个值比较得到相同前缀字节数和剩余的不同后缀部分，把这部分存储起来。比如perform和performance，就得到7ance，对行指针也可以这样压缩

代价是：在索引中查找某个值必须依赖他前边的值，所以无法进行二分查找，只能进行顺序查找，如果进行倒序扫描，速度也会下降，但压缩后只占0.1的空间

### 冗余和重复索引

重复索引：在相同列按照相同的顺序创建相同类型的索引，不应该出现

冗余索引：已有（A，B）这时再加入A索引

## 总结：三原则

* 单行读取很慢，当确定一个数据块后，如果只读取单行，没法避免随机IO，所以尽量使用索引
* 按顺序访问范围数据很快，第一，顺序IO不需要多次磁盘寻道，第二，如果顺序读取数据，就不需要排序操作，group by也不需要多余的操作
* 索引覆盖查询很快，避免了大量的单行查询

# 查询性能优化

## 慢查询的问题：

### 是否请求了不需要的数据？

* 查询不需要的记录：实际上MySQL是先返回全部结果集，再计算。应该加入LIMIT来避免
* 多表关联时返回全部列
* 总是取出全部列：SELECE *
* 查询重复的数据：可以先缓存起来

### 是否扫描额外的记录？

衡量指标：扫描时间，扫描行数，返回行数

#### 访问类型：全表扫描、索引扫描、范围扫描、唯一索引扫描、常数引用

一般where条件执行，从好到坏依次为：

* 在索引中用where过滤不匹配的记录，在存储引擎层完成
* 使用索引覆盖扫描，从索引过滤不需要的纪录，返回名字的结果，在Mysql服务器完成
* 从数据表返回数据，过滤不好的记录，在Mysql服务器层完成

当扫描大量的数据，却只返回少数行：

* 使用覆盖索引，不需要进入数据表找数据就可以返回结果
* 使用单独的汇总表
* 重写查询，让Mysql进行优化

## 重写并优化查询

### 切分查询

将大操作分为小操作

### 分解关键查询

* 让缓存的效率更高
* 减少锁的竞争
* 方便对数据库进行拆分
* 查询效率也会提升
* 减少冗余查询，关联查询可能回事数据被重复访问
* 相当于用应用层的哈希关联代替其他关联

## 如何执行查询

* 客户发送一条查询语句给服务器
* 服务器检查查询缓存，如果有，立即返回缓存中的结构，否，则继续
* 服务器端进行解析器的SQL解析，预处理器的预处理，由查询优化器生成对应的执行计划
* 使用存储引擎的API执行查询
* 将结果返回给客户，并将结果缓存起来

### MySQL的CS通信协议

* 半双工，无法进行流量控制，那么客户端发送查询之后，只能等待，而无法反馈这边已经无法接受，所以Max_Allowed_packet很重要。
* MySQL通常发送结果之后，才释放全部资源，资源存在缓存中，所以今早接受，尽快结束可以缓解服务器端的压力

### 查询状态

对一个SQL连接，会有一个状态

* Sleep：线程等待客户端发送新请求
* Query：正在查询或发送
* Locked：在服务器层等待表锁
* Analyzing and statistics：正在收集统计信息，生成查询计划
* Copying to tmp table 正在将结果集复制到一个临时表中，可能在排序，group by union
* Sorting result：正在对结果集排序
* Sending data：正生成结果集，发送数据

### 查询缓存

如果收到查询语句，解析之前，优先检查查询缓存中的数据是否命中，利用大小写敏感的哈希映射进行查找，如果命中，则会检查一次用户权限，仍然无序解析SQL语句，因为查询缓存已经存放了要查的表信息，若匹配，则返回信息。

### 查询优化处理

将一个SQL语句转化为一个执行计划，MYSQL再依照这个执行计划和存储引擎交互：解析SQL，查询预处理，优化SQL执行计划

#### 语法解析器和预处理器：

* MySQL通过关键字将SQL解析为解析树，并检查合法性
* 预处理器检查权限

#### 查询优化器

* 优化器将解析树转化为执行计划，并在多种执行方法中选择一条最好的
* 优化器选择最优方法时，假设每次读取都要一次IO，什么原因导致选择错误的优化？
  * 引擎提供的统计信息不准确
  * 实际执行的成本和计算的相差很大
  * 最优的不是最快的
  * 不考虑并发
  * 不考虑成本无法控制的操作

查询优化分为静态优化（编译优化）和动态优化（执行优化）：

* 重定义关联表的顺序
* 外连接转为内连接
* 使用等价变换规则
* 优化Count，max，min
* 转化为常数表达式
* 覆盖索引扫描
* 子查询优化
* 提前终止查询：limitt
* 等值传播
* 列表in的比较

#### 如何执行关联查询：

* MySQL认为每一次查询都是一次关联查询，对任何关联查询执行嵌套循环关联操作：在一个表中循环取出单行数据，再嵌套循环到下一个表中寻找匹配的行，再根据所有的结果，返回需要的列。在最后一个关联表中找到所有匹配的行，没有则返回上一层
* 执行计划总是一个左侧深度优先的树

#### 关联查询优化器：

* 在不同的关联查询方案中，选择一个代价小的关联顺序

#### 排序优化：

* 当不能使用索引进行排序，需要Mysql自己排序，数据下就在内存，数据大就在磁盘
* 当需要排序的数据小于内存缓冲区，在内存中进行排序，如果不够，则进行数据分块，对每个独立的块进行排序，结果存放在磁盘上，最后进行合并即可

两种排序算法：

* 两次传输排序：读取行指针和需要排序的字段，对其排序，再根据排序结果读取需要的行，需要两次读取，第二次为随机IO，但排序时也能容纳更多数据，毕竟只读要排序的那一列
* 单次传输排序

排序会额外为每一行安排额外空间，有时候非常占地方

结果集返回是一个逐步的过程，可以边查询便返回，一旦客户端处理完最后一个关联表，生成结果集时，就可以这样

## 查询优化器的局限性：

* 关联子查询：尽量把关联子查询换成内连接，where中的IN
* UNION的限制：无法把外层UNION推到内层，比如Limit、
* 等值传递：有一个非常大的IN列表，MYSQL发现有一个条件子句，把这个列表和其他列关联，于是把这个IN列表复制到各个表中，会非常慢
* 没办法利用多核特性并行执行
* 无法使用松散索引，无法违法最左匹配原则
* 不支持在同一张表上查询和更新

### 设置查询优化器的提示：

* 高低优先级：设置多个语句的优先级
* DELAYED：对更换和插入，将该语句立即返回给客户端，将数据写入缓冲区，合适时机统一冲刷到磁盘
* STRAIGHT JOIN，用在select中，让查询的所有表按照语句的顺序关联，用在两个关联表名字之间，固定两表的关联顺序
* SQL SMALL RESULT 表示select语句中的GROUPBY和DISTINCT如何对临时表排序，在内存或者磁盘
* SQL BUFFER RESULT：将结果放入一个临时表，并尽快释放表锁
* SQL CACHE 结果集是否因该放在查询缓存中

## 优化特定查询

### 优化count查询：

count做什么？如果不传参数，就是统计行的数量，如果传参数，就是统计这一列非空值的数量

MyISAM的COUNT很快？如果不传参数吗，就是很快，如果传参数，就不快了

优化：取反计算，取近似值

### 优化关联查询

* 确保ON或者USING子句的列上有索引，考虑关联的顺序，如果是A用c列关联B，那么只需要在B的c列建立索引即可，没有必要在第一个表上建立索引
* 使GROUPBY或者ORDERBY只涉及一个表中的列，这样就可以利用索引
* 升级时，关联语法和运算符优先级会由普通关联变为笛卡尔积，生成不同的结果

### 子查询尽量变为关联查询

### 优化GROUP BY和DISTINCT

使用索引优化

* 在GROUPBY中，如果不能使用索引，那么可以使用临时表或者文件排序进行分组

### 优化LIMIT：

当使用索引时，效率很好，如果没有索引，需要做很多文件排序任务。

问题：当表很大的时候，需要顺序读取前边所有的行，最后得到需要的很少一点数据。

解决办法：

* 使用索引覆盖扫描，再做一次关联操作返回所需的列
* 也可以将LIMIT查询转换为对一直范围的查询，通过范围扫描得到对应的结果
* 使用书签

### 使用SQL_CALC_FOUND_ROWS

在LIMIT中加入SQL_CALC_FOUND_ROWS，可以去掉LIMIT以后满足条件的行数，可以作为分页的总数。本质上，这条语句会强迫mysql扫描所有满足条件的行，而不是到达LIMIT就停止扫描，所以代价很高。

### 使用用户自定义变量

缺点：

* 自定义变量的查询无法使用查询缓存
* 不能再表名，列名和LIMIT子句使用
* 自定义变量在一个连接内有效，所以不能当作连接间通信
* 使用连接池和持久化连接容易出问题
* 无法声明自定义变量的类型
* 优化器有时会将变量优化掉
* 赋值顺序和时间由优化器决定
* 赋值符号的优先度很低
* 未定义变量不会出现语法错误

## 分区表

* 对用户，分区表是独立的逻辑表，在底层分区表是物理上分开的多个子表，实现分区的代码是对一组底层表的句柄对象的封装，对分区表的请求，都会通过句柄对象转化为对存储引擎的API调用
* MYSQL对底层表进行封装，索引也是按照分区的子表定义，所以没有全局索引
* 创建表使用PARTITION BY定义每个分区存放的数据，在查询时，优化器根据分区定义过滤无用分区，减少扫描分区数

分区的优点：

* 存放热点数据，隔离历史数据
* 方便维护数据
* 分布式存放
* 避免大量锁机制
* 备份和恢复更方便

限制：

* 无法使用外键约束
* 主键列和唯一索引列必须包含
* 可以直接使用列进行分区，或者指定整数
* 一个表最多由1024分区

### 分区原理

* 分区表由多个相关的底层表实现，这些底层表是由句柄对象表示，分区表索引就是在数据外加一个完全相同的索引
* 存储引擎无需知道这是分区表还是普通表

操作逻辑

* SELECT：分区层打开并锁住所有的底层表，优化器先判断是否可以过滤部分分区，在调用部分存储引擎接口访问各个分区的数据
* INSERT：分区层打开并锁住所有的底层表，确定哪个分区接受这条记录，再写入
* DELETE：分区层打开并锁住所有的底层表，确定数据对应的分区，删除
* UPDATE：分区层打开并锁住所有的底层表，MySQL确定要更新的记录在那个分区，取出数据并更新，再判断放回的数据属于那个分区，写入，再将原数据删除

### 分区策略在什么情况下或会出问题？

* NULL值会让分区过滤无效，如果分区表达式为NULL，那么所有无效值会被放到第一个分区，但在每次查询时，会检查第一个分区和符合条件的分区，会让你扫描额外的行

* 分区列与索引列不匹配，导致查询无法进行分区过滤，进行全区扫描

  假设a列本身有索引，但是对b列进行分区，因为每个分区都有独立的索引，扫描列b的索引就等于扫描每个分区的索引，如果索引都在内存中还好

* 选择分区的成本高

  对于范围分区，查询某行属于哪个分区的成本很高，对于按行写入大量数据尤甚，对哈希分区和键分区则不然

* 打开并锁住所有底层表的成本很高

  这个操作在分区过滤前发生，无法降低分区数量来减少加锁操作。可以使用批量执行的方法改善

  维护分区的成本很高

分区表的限制：

* 所有分区使用相同的存储引擎
* 分区函数使用存在限制
* MyISAM无法使用LOAD INDEX INTO CACHE
* 需要打开很多的文件描述符

### 视图：

* 视图本身是一个虚拟表，不存放数据，再使用SQL语句访问视图时，他返回的数据是MYSQL从其他表中生成的。
* 不能对视图使用触发器，不能DROP TABLE删除视图
* 如果视图包含GROUPBY，DISTINCT，聚合函数，UNION，子查询等，就不能在原表记录和视图记录建立映射，就要使用临时表进行。
* 视图算法分两种：
  * 临时表法
    * 用户发起含有视图的查询
    * 服务器解析查询
    * 服务器执行定义在底层表上的视图SQL，服务器重写查询使用的临时表
    * 服务器将数据保存在和视图结果一样的临时表中
    * 将结果返回
  * 合并算法：
    * 用户发起SQL查询到视图
    * 服务器解析查询
    * 服务器将视图SQL和查询SQL合并
    * 服务器基于底层表执行SQL查询
    * 返回数据

## 外键约束

InnoDB支持外键约束

* 外键具有成本，每次修改数据，都要在另外一张表多执行一次查找，虽然强制外键使用索引，但是这个查找还是会消耗，而且碰上选择度很低的外键，会很失败
* 但外键是保证两个表一致性的银弹，但外键操作时逐行更新的，这样会比批量更新慢
* 使得查询需要对额外的表加锁，访问额外的行

## 在MYSQL内部存储代码

* 允许通过触发器，存储过程，函数存储代码，也可以用定时任务，叫做事件，存储程序
* 优点
  * 在服务器执行，节省带宽
  * 代码重用
  * 简化代码维护
  * 提升安全，细粒度的权限控制
  * 可以缓存存储过程的执行计划
  * 备份维护都可以在服务器端进行
* 缺点：
  * 存储代码效率查，函数有限
  * 无法控制资源消耗，如果出小问题，可能吃光资源
  * 异常处理很弱
  * 不好调试

### 存储过程和函数（存储程序）

限制：

* 优化器无法评估存储函数的执行成本
* 优化器无法使用DETERMINISTIC优化单个查询多次调用存储函数的情况
* 每个连接都有独立的执行计划缓存，若多个连接要调用同样的存储过程，会多次缓存
* 不能复制对存储程序的调用

### 触发器

触发器可以在执行INSERT，DELETE，UPDATE时，前后执行一些特定操作，没有返回值，但是可以读取或者改变数据

* 一个事件只有一个触发器
* 只有基于行的触发，如果变更范围很大，效率降低
* 可以保证数据总是一致的，但无法保证原子性，无法触发回滚操作。

### 事件

* 事件在一个独立事件线程被初始化，他和连接线程无关，不接受也没有返回值，
* 防止并发的事件：统一个事件，上一个事件还没有处理完，下一个时间已经开始了
* 多个事件可以并发

## 游标

* 游标指向的对象存储在临时表，而不是实际数据，所以总是只读的
* 当游标只需要遍历一个大结果集的一小部分，那么可以使用limit限制，不然会在打开游标时全部读出来
* 临时表不支持存放BLOB和TEXT，如果游标读取的结果包含这些列，那么就会在磁盘中创造临时表，或者当临时表空间大于Tmp table size也会去磁盘

## 绑定变量

* 当创建一个绑定变量SQL时，客户端向服务器发送一个SQL语句原型，服务器收到SQL语句框架，解析并执行SQL的部分执行计划，返回给客户端一个语句处理句柄，以后每次执行查询，客户端都用这个句柄，使用问号标记参数的位置
* 可以向服务器发送句柄和问号的值，决定一次查询的SQL语句
* 服务器端只需解析一次SQL语句
* 因为优化器会缓存执行计划，所以优化器的工作只要执行一次
* 用二进制的方式发送参数和句柄，比ASCII发送效率高
* 网络开销更小
* 减少SQL注入的风险

#### 优化

如果某些执行计划需要传入参数，才能得到执行计划，就无法缓存这部分执行计划，可以把优化分三类

* 准备阶段：解析SQL时，移除不可能的条件，重写子查询
* 第一次执行：简化嵌套循环的关联，将外连接转为内连接
* 每次执行：
  * 过滤分区
  * 移除COUNT MAXMIN
  * 移除常数表达
  * 检测常量表
  * 必要等值传播
  * 优化关联顺序

#### 问题：

* 绑定变量时会话级别，一旦连接断开，就无法使用原来的句柄进行
* 老版本，绑定变量SQL无法使用查询缓存
* 如果只执行一次SQL，就不用使用绑定变量

## 字符集

字符集：二进制编码到字符符号的映射

校对：某个字符集的校对规则

#### MYSQL规定字符集的设置：

创建对象的设置：MYSQL的默认字符集和校对规则每个库和每个表都有，规定了应该用什么字符集存储某个列

* 创建数据库时，根据服务器上的character set server设置决定数据库的默认字符集
* 表根据数据库的默认字符集
* 只有当没有指定列的字符集，才使用列根据表的设置

#### 服务器和客户端通信的设置

* 服务器假设客户端按照自身的默认字符集通信，发来character set client
* 当收到信息，按照character set connection将其转换为字符集
* 当返回信息或者错误，要转化为character set result

## 全文索引

### MyISAM的全文索引：

一种特殊的B-树，第一层是所有关键字，第二层是文档指针

* 不会索引停用词
* 长度超出范围不会索引

### 自然语言全文索引

* 计算每一个文档和查询的相关度，基于匹配关键词的个数和次数。
* 非常常见的词语不会搜索，如果一个词在超过50%的词语中出现了
* 使用两次match不会有太大消耗，因为会自动识别并只进行一次计算

### 布尔搜索

* 在查询中自定义某个被搜索词语的相关性
* 要求搜索词语不是停用词，要求词语长度
* 只有MyISAM引擎才可以使用布尔全文索引

### 缺陷：

* 全文索引依赖词频进行搜索，无法考虑词的位置信息
* 只有数据全部在内存时，速度才可以接受
* 速度受列长度影响
* 影响查询优化器的工作
* 不可能使用索引覆盖扫描，因为全文索引不存储列的实际值
* 不能用作列的其他排序
* 如果查询中使用了MATCH AGAINST。对应列上有可用的全文索引，那么优化器就不会评估其他索引
* WHere等条件必须等待全文索引完成后，在进行查找

### 技巧：

* 缓存全文索引的主键值，当真的需要输出，再将主键值的数据返回
* 如果InnoDB需要全文索引，那么将数据复制到备用库，然后改为MyISAM，或者将需要索引的列冗余存储再另一个MyISAM中，只要得到行指针即可

### 优化：

* 全文索引有很多碎片问题，所以要经常进行OPYIMIZE TABLE
* 提供一个好的停用词表
* 提供好的最小长度和最大长度
* 当需要导入大量数据到全文索引表，需要先关闭全文索引，在导入结束后再打开索引，因为key的更新很麻烦

## 分布式事务

MySQL能在存储引擎级别实现ACID，也可以把ACID的事务特性扩展到多个数据库层面

* 第一阶段，事务协调器需要保证所有的事务参与者完成了准备工作
* 第二阶段，如果协调器知道所有参与者都准备好，就示意所有的事务都可以提交了
* MYSQK扮演参与者

### 内部XA事务

* MYSQL本身的插件式架构导致在内部也要使用分布式事务
* 如果有一个跨存储引擎的事务，那么就需要保证事务再两个不同存储引擎的表中保留ACID特性
* MYSQL的binlog可以看作一个独立的存储引擎，向存储引擎提交的同时，也要向binlog提交，使用它导致无法使用批量写入，而必须调用fsync，必须对二进制日志进行一次持久化操作，对事务日志进行2次持久化操作，一共三次
* 如果要避免，则要将二进制日志关闭，也要将innodb support xa关闭，这样导致MYSQL复制无法进行，最好将sunc binlog设置为1，这样存储引擎和二进制日志才是同步的

## 查询缓存

* 不同于缓存相似的SQL语句的执行计划，跳过SQL解析和执行计划生成阶段，查询缓存缓存完整的查询结果，如果查询命中缓存，并具有访问权限，那么就不需要之后的操作，跳过了解析优化和执行。
* 如果所查询的表发生了变化，那么对应的查询缓存就会被清空
* 查询缓存对用户完全透明

### 如何判断缓存命中？

* 缓存放在引用表里，通过哈希查找，哈希值包括了：查询本身、查询的数据库、协议版本等
* MYSQL不会解析SQL语句，而是直接使用
* 不确定的语句结果不被缓存（用户自定义函数、变量、存储函数、临时表、系统表、列级别权限表），查询时检查SQL语句是不是SEL开始的。
* 对读和写操作的影响：
  * 读操作开始前，先检查是否命中
  * 读操作完成后，将数据顺便写入缓存
  * 写数据时，必须将关于此表的缓存失效
* 缺陷：事务的特性会限制查询缓存，InnoDB会将写数据时，将关于此表的缓存失效这个事件对其他事务屏蔽，在这个事务提交前，其他查询无法被缓存，必须等待完成后才能缓存，长时间运行的事务会降低缓存的命中。如果缓存中有大量数据，缓存失效会获取一个全局锁，此时其他查询会一直等待这个锁，会慢。

### 

## MYSQL的配置原理

* MYSQL从配置文件和命令行参数获取配置信息

* 配置文件的位置：/etc/my.cnf或者/etc/mysql/my.cnf

* 配置项可以有多个作用域，全局作用域作用域整个服务器，每个连接不同，或者每个对象不同

### 常用动态设置变量设置和结果：

* key_buffer_size

  一次性为键缓冲区设置大小，但是大小是逐渐分配的，不是一次性完全分配

  * 如果把非默认键缓存空间设为0，MYSQL会丢弃存在键缓存在对应的索引，而使用默认键缓存，并且在无引用时删除键缓存
  * 如果为不存在的键缓存设置为某值，则会创建新的键缓存
  * 对一个已经存在的键缓存设置非0值，会刷新键缓存的内容，会阻塞所有试图使用键缓存的操作

* table_cache_size

  不会立即生效。直到下次打开表才会产生效果，每次打开表，线程会检查这个值，并调整缓存在表的大小

* thread_cache_size

  不会立即生效，下次有连接被关闭时才产生效果，关闭一个链接，会检查是否还有空间缓存线程，有的话，就不关闭线程，等待下次继续使用

* query_cache_Size

  启动时分配并初始化内存，如果修改，立即删除所有缓存的查询，重新分配指定大小的存储空间，这段时间服务器都无法提供服务

* read buffer size

  只有在需要时菜分配缓冲空间，分配指定的大小

* read buffer size

  分配需要的大小，而不是指定的大小

* sort buffer size

  只有在需要排序时才分配大小，直接分配指定内存

## InnoDB事务日志

* InnoDB使用日志减少提交事务的开销。通常，事务修改的数据和索引会映射到表空间的随机位置，这代表着随机IO，因为移动磁头的时间占用很多，
* 日志把随机IO换成顺序IO，变更写入日志和数据文件两个地方，就算写入日志后出现了断电，也可以从日志上回复
* 日志有固定大小，使用环形方式写入，逐条向下记录，写满之后从首部记录。但不会覆盖还未持久化的变更记录。
* 一个固定的后台线程刷新变更到数据文件中，可以批量组合读写，使写入成为顺序IO，批量刷新操作放到这个线程，可以缓和查询高峰的后台IO压力
* 日志文件受制于innodb log file和innodb log file in group的大小，高性能需要大一些
* 多个文件作为一组循环日志，不需要修改日志数量，只需要修改大小即可，首先关闭MYSQL，将旧的日志文件存到其他地方保存，重新配置参数，然后重启。重启后，查看错误日志，没有错误之后才可以删除旧的日志文件
* 如果日志大小过于小，则设置更多的冲刷频率，有更多的检查点。如果日志的大小过大，则在崩溃恢复的时候，要更长时间
* 当InnoDB变更数据时，会写一条变更记录到**内存日志缓冲区**，当满足“缓冲满的时候”或者“事务提交的时候”或者“每一秒钟”，就会刷鞋缓冲区的内容到磁盘日志文件。如果有较大写入，可以增加内存日志缓冲区的大小，来减少IO（1-8MB），日志条目尽可能地短小
* 日志文件的大小，应该满足一小时服务器的写入
* InnoDB如何刷新日志缓冲？当需要把内存日志缓冲区的记录写到磁盘日志文件，需要先用一个Mutex锁住缓冲区，刷新到所需要的位置，然后移动剩下的条目到缓冲区的前面，如果刷新完毕要释放Mutex，可能有很多事务要刷新日志记录，Group Commit在二进制日志下不能使用，可以使用innodb flush log at trx commit控制日志缓冲刷新频率：0每秒刷新，刷时不做其他事，1每次事务提交刷新，2每次提交
* 0：首先把内存日志缓冲写到操作系统内存，然后每秒刷新到磁盘日志文件
* 1：首先把内存日志缓存写到操作系统内存，每次事务提交都刷新到磁盘日志文件，可保证不会丢失任何已提交的数据
* 2：每次提交都把内存日志缓存写到操作系统内存，不刷新，每秒刷新到日志文件

### InnoDB表空间

* InnoDB把数据保存在表空间，是一个由若干个磁盘文件组成的虚拟文件系统。
* 表空间保存了文件和索引，回滚日志，插入缓存，双写缓存，回收空间的方法只有导出数据，删除数据，修改配置，重启，创建新的数据文件，然后导入数据：不能简单地删除或者改变大小
* 可以配置innodb——file——per——table为每张表使用一个文件，可以方便设置表空间，也利于减少碎片，因为如果使用多个文件表示一个表，会有更多的碎片分布在很多文件，因为innoDB最小页时16KB，当你需要1KB的数据，也要使用16KB的磁盘。这个参数会带来更差的DROP TABLE性能，会导致服务器阻塞：
  * 在文件系统上删除表很慢，更多的是，暂时把.ibd文件指向一个0字节的文件，再合适的机会在删除
  * 当每张表使用自己的表空间，移除表空间，需要InnoDB锁定和扫描缓冲池，查找属于表空间的页面，再缓冲池比较大的时候这样做是很浪费时间的。

### 行的旧版本和表空间

* 在写压力很大的时候，InnoDB的表空间可能会增长的很大，如果事务保持打开状态很久，使用默认的可重复读，InnoDB无法删除旧的行版本，那么表空间会无限增大，当清理线程跟不上更新速度，也会让表空间变大
* 没有清理的行版本，实际上让索引和表更大了，会拖慢速度
* 控制写入速度来配合清理线程的速度 ：innodb_max_perge _lag

### 双写缓冲

* innoDB使用双写缓冲避免页没写完整导致的数据损坏：当一个磁盘写操作不能完整的完成时，不完整的页写入会出现，16KB的页只有一部分被写到磁盘上
* 双写缓冲是表空间一个保留区域，将一个最近写回页面的备份拷贝，当InnoDB从缓冲池刷新页面到磁盘，首先把他们写到双写缓冲区，然后再把他们刷新到目标磁盘数据区域。保证每个写入操作是原子化，持久化的
* 每个页要写两次，但是因为是顺序IO，并且是调用一次fsync到磁盘，所以压力比较小，而且给了数据不会损坏的保证，所以二进制日志文件并不需要保留完整的数据，只保留数据的二进制变化量即可
* 若一个不完整的页写到了双写缓冲，原始的也依然会在磁盘的位置，当进行恢复时，会先用原始页面替换双写缓冲的损坏页面
* 若双写缓冲成功，但是写到页的真实位置的尝试失败，InnoDB会将双写缓冲的拷贝替换真实页。
* 如何检查页损坏？使用检验和

![img](https://img-blog.csdnimg.cn/20210325014100172.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2l0X2xpaG9uZ21pbg==,size_16,color_FFFFFF,t_70)

### 二进制日志从缓存写到磁盘的频率：

sync_binlog默认设置为0，表示mysql不管理刷新操作，由操作系统决定，但可以设置为比0大的值，表示多少次写操作之后刷新日志内存，写操作代表事务执行次数，如果设置自动提交的话，那就是事务独立语句次数

## MYISAM的IO配置

### 索引：

* 每次写操作，MYISAM都会更新索引，刷新磁盘，所以使用批量操作更快

* 也可以使用延迟写操作：delay_key_write：

  * OFF：每次写入都会刷新键缓存，除非表被锁
  * ON：延迟键写入
  * ALL：所有表都会延迟键写入

* 缺点：

  * 因为延迟了所以可能会丢失修改，索引损坏
  * 关闭表必须等待所有延迟的修改写入，会有很长的时间等待
  * FLUSH table会等待较长的时间
  * 没刷进去的脏块很占内存

## MYSQL并发

### InnoDB并发

* 并发值=cpu乘磁盘数量*2，使用 innodb_thread_concurency控制一次性有多少线程可以进入内核
* 如果进入内核的线程数达到允许的线程数,线程首先休眠innodb_thread_sleep_delay(1000)微秒,之后再次请求,还不能进入内核,则进入等待队列。
* 如果有大量小查询，则可以设置更小的休眠时间
* 线程进入内核，就会获得若干（innodb_concurrent_ticket）票据，从而可以不经过并发检查而进入内核，限制了一个线程可以进行多少查询。票据按照查询授权，不是事务。
* 提交的并发：innodb_commit_concurrecy控制多少个线程可以在同一时刻提交

### MYISAM并发

MYISAM如何删除和插入行？

* 删除行，把行标记为删除，然后留下一个洞
* 插入行，尽量重新利用空洞，如果没有空洞，则插入到表末尾。
* 并发：尽管具有表锁，但仍然可以便读取，边并发的插入，新插入的数据是不可见的。只是插入的行对读取的线程不可见，但没办法避免表中空洞的不一致性，读取还是会读到
* 设置concurrent_insert，可以配置并发插入，0不允许，插入附带互斥锁，1表中没有空洞，就可以并发插入，2强制插入到表末尾，不利用空洞，会让表碎片化。
* MYSIAM的Mutex：键缓冲区的全局Mutex降低并发，因为刷新键缓冲区到磁盘会导致阻塞，改进后对每个键缓冲区有一个Mutex锁，但仍然有并发问题

### 优化BLOB和TEXT

* MYSQL无法在内存临时表中存储BLOB和TEXT，所以任何查询都会在磁盘创建临时表这是很浪费时间的
* 方法一：可以使用SubString函数把BLOB转化为VARCHAR让查询可以在内存中进行，甚至可以对其创建索引
* 方法二：可以把BLOB放入基于内存的文件系统中
* 对很长的BLOB类，InnoDB存储一个前缀，如果列的值比前缀长，会在行外分配拓展空间，，会分配一个完整的16KB的页，每个列都有自己的拓展空间，
  * 大字段可能会在innoDB中浪费大量空间
  * 禁用了自适应哈希索引。需要逐字比较
  * 太长的值无法使用where进行索引
  * 最好把一张表的大字段放在一起进行存储

### 优化排序：

* 如果查询的列和ORDER BY的列总大小超过了max_length_for_sort_data字节，就使用two-pass方法，或者当任何列是BLOB类，也会是two pass，不然就是single pass方法
* 可以修改max length for sort data，因为single pass要为每一行排序的数据分配一个固定大小的缓冲，而VARCHAR使用最大长度，而不是实际占的长度
* 必须排序BLOB时，只是用前缀，忽略剩下的，因为缓冲只能分配固定大小的结构保存要排序的值。

### 其余配置：

* tmp table size/tmp heap table size：控制内存临时表能使用多大内存，如果内存临时表超过，将会被转为磁盘临时表
* max_connections：保证服务器最大连接数不会超过这个值
* thread_chache_size：设置线程缓存的大小值
* table cache size：表缓存大小，应该大一些，避免频繁打开和解析表

### 安全配置：

* expire log days：设置清理过期日志的指定时间间隔，不清理的话会让日志文件大小一直很大
* max allowed packed：防止服务器发送过大的包，防止客户端发送过大的包，可能会让备库无法接受主库大包
* max connect error：连接故障出现次数达到这个数字，会让客户端无法连接，直到刷新主机缓存
* skip name resolve：禁用DNS查找，避免DNS解析和验证时发生较长时间的阻塞（用户名，密码，主机名）。禁用之后，要把基于主机名的授权，改为基于IP的授权
* sql mode：修改方言

### 对于备库：

* read only：禁止没有特权的用户在备库做变更，只接受主库的数据
* skip slave start：阻止MYSQL自动启动复制，防止在不安全的崩溃后自动复制，需要手动检查服务器，手动复制
* slave net timeout：和主库断开连接之后，重连之前的等待时间
* sync master log,sync relay log, sync relay log info:解决“备库不把文件复制到磁盘，崩溃后要人为猜测复制的位置在主库中相对的位置”，这些选项更容易使备库从崩溃中恢复，但也带来了多一次的fsync调用

### 高级InnoDB设置

* innodb：FORCE：只有在innodb启动，服务器才启动
* innodb autoinc lock mode：控制如何生成自增主键，如果有很多事务等待自增锁，就要调整
* innodb buffer pool instance：把缓冲池切分为多段，可以在每一段分配Mutex锁，增加并发性能
* innodb io capacity：告诉innodb服务器的IO能力，可以适当提升性能，因为innodb默认认为服务器的IO性能不好
* innodb read/write io threads：多少个后台线程可以被innodb使用
* innodb strict mode：让警告变成报错

### 随机IO和顺序IO

* 顺序IO和随机IO当然是随机IO更快，因为随机IO要花大部分时间在磁头的移动上，使用缓存可以大大提升随机IO的性能，因为可以把热点数据存储在内存中，避免大部分磁头的随机移动。顺序存储只需要扫描一遍数据，缓存的用处不大，除非能够把所有的文件都放在内存中
* 顺序读取不能从缓存中收益的原因：
  * 顺序IO比随机IO快
  * 存储引擎执行顺序读比随机读快：对于InnoDB和MyISAM都要读一个链表

### MYSQL在固态硬盘上进行优化

* 增加InnoDB的IO容量
* 让InnoDB的日志文件更大，崩溃恢复需要随机IO，而固态硬盘可以带来随机IO的提升
* 把日志文件从闪存转移到RAID，因为日志是顺序IO，
* 禁用预读
* 配置InnoDB刷新算法
* 禁用双写缓冲，因为固态硬盘支持16KB的原子写入
* 减少插入缓冲的大小：插入缓冲用来减少当更新行时，不在内存中的非唯一索引引起的随机IO

### 内存交换

* 当操作系统因为没有足够的内存，于是将一些虚拟内存写到磁盘上就是内存交换，内存交换对用户进程不可见
* 内存交换会导致性能急剧下降，假如MYSQL认为当前某数据还在内存，于是使用Mutex锁锁住内存，进行操作，但这时候，该数据已经发生了内存交换，于是，就需要很长时间的IO操作，而且这段时间其他访问内存的操作全部阻塞。这意味着内存交换IO还不如直接去磁盘IO。
* 太多的内存交换会让操作系统交换空间溢出，可能会让MYSQL崩溃，
* 特别大内存压力的情况下，可能会kill一些进程。

## 复制

* 复制本质上让一台服务器和其他服务器保持同步
* 基于行的复制和基于语句的复制都是通过在主库上记录binlog，在从库上重放这些文件进行异步的复制
* 复制增加主库IO开销和网络开销，增加从库的加载Binlog开销。
* 复制的特点：
  * 提供数据分布
  * 提供负载均衡
  * 提供备份
  * 高可用性和故障切换
  * 升级测试

### 复制细节：

* 步骤一：在主库上把记录更改到二进制日志上。
* 步骤二：备库将主库的日志复制到自己的relay log上
* 步骤三：备库重放relay log，将改动作用于数据上

对于步骤一：

* 每次提交事务完成更新前，主库都将数据更新的事件记录到二进制日志上。会按照事务提交的顺序来记录二进制日志文件。记录之后，主库就可以提交事务了

对于步骤二：

* 备库将主库的二进制日志文件记录到自己的relay log上。首先备库启动一个工作线程，叫做IO线程，IO线程和主库建立一个客户端连接，然后主库启动一个二进制转储线程，此线程会读取主库的二进制日志事件，如果线程追赶上了主库，他就会进入休眠，知道主库有新的事件产生，他会被唤醒，备库IO线程会将接收到的IO事件记录到中继日志上。

对于步骤三：

* SQL线程从中继日志中读取事件，并在备库执行，实现更新，当SQL线程追赶上IO线程时，中继日志已经在系统缓存中，所以日志开销很低。SQL线程的事件可以选择是否写入自己的二进制日志中

## 配置复制：

* 在每台服务器上创建复制账号
* 配置主库和备库
* 通知备库连接到主库并复制

### 从一台已经运行的服务器上复制

需要有三个条件：

* 具有某时间点数据快照
* 具有主库当前二进制日志文件，和快照在二进制文件中对应的偏移量
* 从快照时间到现在的二进制日志

### 复制配置：

* sync binlog=1，会导致事务提交前先写入二进制日志中，可以避免服务器崩溃而让事务丢失。但带来了额外开销。
* 无法容忍表损坏就用innodb，可以容忍就是用MyISAM。在备库服务器崩溃重启时，备库数据表可能不一致，比如某个语句没有完全应用到表中，这时即使重新修复也是不一致的。
* 使用innoDB时，要保证事务性，主库就要设置：innodb support x = 1, innodb flush logs at trx commit，innodb safe binlog，开启分布式存储，每次提交都刷新缓存到binlog，备库设置：skip slave start ，readonly，跳过自动复制，开启只读，备库开启sync master log,sync relay log, sync relay log info，记录每次崩溃后备库复制主库的进度。
* 如果延迟过大，写入很多中继日志，会导致中继日志过大，重放速度跟不上，这时要设置relay log space limit，如果IO线程接受的多于这个值，IO线程会暂时休眠

## 复制：

### 基于语句的复制：

基本就是重放一次SQL语句

#### 优点：

* 不占带宽，也能保持方便的同步

#### 缺点：

* 有些SQL语句无法复制：包括CUrrent USER函数的
* 更新必须是串行的，必须要很多锁来实现。
* 无法和触发器和存储过程配合使用

### 基于行的复制：

将实际数据记录到二进制日志中，可以正确复制每一行

* 减少锁的争用
* 占用更少的CPU
* 更快找到数据不一致的错误
* 比较难找到执行了哪些SQL

### 复制文件：

- mysql bin.index：和二进制日志相伴而生，记录磁盘上的二进制文件，每一行包含了一个二进制日志文件名，如果没有它，MYSQL无法识别二进制日志文件
- mysql relay bin.index：在从库起一样的作用
- master.info：保存备库连接到主库需要的信息，每行一个值，纯文本，没有他会再重启之后无法连接主库，也保存了连接密码，不能泄露
- relay log.info：保存了备库复制的二进制日志和中继日志坐标，没有的话，就无法在恢复时找到目前复制到主从哪里了。
- expire log days与.index互相配合，缺少了index，自动清理就没用了。

### 发送复制事件到其他备库

* log slave updates可以让自己变成别人的主库：备库执行了relay log的某个事件，本开应该抛弃这个事件，但是现在需要设置binlog，并将binlog发给备库
* 要给每个服务器分配一个唯一的服务器ID：为了在复制过程中防止无限循环，当重放中继日志时，会丢弃那些服务器ID和本机ID一样的记录，不然会出现主主结构中的无限循环复制
* 几乎不能假定拥有同一逻辑复制点的服务器有相同的日志坐标

### 复制过滤器

复制过滤选项可以指复制服务器上的一部分数据，有两种过滤方法：在主库中过滤记录到二进制日志上的事件，或者在被苦衷过滤记录到中继日志的事件

* 在主库上使用binlog do db 和binlog ignore db设置什么要做和什么要过滤
* 在从库上使用replicate *控制应该从中继日志上过滤什么，也可以使用 do db和ignore db过滤当前默认数据库，用错就导致主从不同步

## 复制拓扑

拓扑原则：

* 一个从库只有一个主库
* 每个从库有一个独立的ID
* 一个主库可以有多个从库
* log slave update可以将从库视为主库

### 一主多从：

* 备库无交互
* 适合少量写大量读的情况，把读分摊到备库上。但备库不能无限增加，直到备库给主库造成负担。
* 用途
  * 不同的角色使用不同的备库
  * 一台备库当作备用主库，只有复制，没有读写
  * 延迟一个备库，或者将一个备库放在不同的机架，用作灾难恢复
  * 使用一个备库当作测试数据库

### 主主复制：

* 一对主库，但不支持多主库复制
* 设置auto increment increment和auto increment offset，让MYSQL为INSERT语句选择互不冲突的值。但这样的双主模式很麻烦

### 主动-被动的主主复制：

* 与之前的主主复制区别的是，有一台是只读的被动服务器
* 可以执行对称变换，出现错误的时候，可以在不关闭服务器的同时维修：对于ALTER TABLE，可以先停止日志复制线程，在从服务器上进行改表操作，完成后将主服务器的写入复制过来，再更换角色
* 如何配置主主服务器对：
  * 确保两台服务器数据相同
  * 启动binlog，选择唯一的ID，创建复制账号
  * 启动备库的relay log
  * 被动服务器改为只读
  * 启动MYSQL
  * 将主库设置为对方的备库，使用新创建的binlog开始工作。

### 有备库的主主结构

* 可以考虑为每个主库增加一个备库
* 可以增加冗余，负载均衡

### 环形复制：垃圾

当某人宕机则，会产生无限复制

### 主库、分发主库、备库

* 当备库太多，会给主库造成负载压力，因为每个备库会在主库上创建一个日志转储线程，执行binlog dump命令，会读取binlog中的数据并发送给备库，多个日志转储线程不会共享binlog dump资源。如果有一个很大的写入，同时有很多备库进行请求，主库会耗尽内存并崩溃，如果备库请求的数据不在缓存中而在磁盘中，会带来巨大的IO压力，并且也有锁争用。
* 解决办法：使用分发主库，这个库是主库的一个备库，只负责二进制日志的备份和发放。分发主库进行日志过滤也很高效，缺点是备库无法升级为主库，因为这样有违拓扑结构

## 定制的复制方案：

### 选择性复制

* 只将需要读的数据复制到备库中，可以更好的利用备库的内存，将工作集放在备库的内存中。每个备库只有主库一部分的写入负载，主库的写入延迟就降低了。
* 或者将主库不同的数据库分发给不同的备库。和使用black hole引擎的分发主库进行配合

### 分离功能

* 分离OLTP在线事务处理和OLAP在线数据分析，前者查询为多次较短较快的事务性查询，后者为少次较长较慢的大数据请求，不太在意数据是否新

### 数据归档

* 在备库上保留主库删除过的数据。可以在主库上选择的禁用二进制日志，或者在备库上使用replicate ignore db

### 全文检索

* 备库实现全文检索，选择更适合全文检索的引擎和索引

### 只读备库

### 模拟多主库复制

* 将一台备库轮流指向多台主库，如果主库的负载很低，而且不会出现冲突，需要为每个主库跟踪二进制日志坐标。
* 也可以使用主主复制结构，但是备库只连接其中一个主库，从中读取两个库的binlog，被链接的库保存另一个库的binlog和自己的数据与binlog。

### 创建日志服务器：

日志服务器的目标是：更方便的重放，更省事的过滤日志

## 从库的升级

### 计划内的提升：

* 停止向老库写入
* 让备库追赶上主库（先kill所有事务，再将主库设置为read only）
* 将一台备库刷新为主库（STOP SLAVE,CHANGE MASTER TO，RESET SLAVE使其断开与主库的连接，SHOW MASTER STATUS获取日志坐标）
* 将备库和写操作指向新的主库（CHANGE MASTER to 之前的二进制坐标）（会丢失master.info的信息，所以不要把连接信息卸载master.info）

### 计划外的提升：

如果已经开启了log bin和log slave update，那就可以保持一致性

* 确定哪一台备库的数据是最新的，检查 SHOW SLAVE STATUS选择日志坐标最新的备库
* 让所有备库执行完从主库复制的中继日志，
* 在新主库上执行STOP SLAVE，改写CHANGE MASTER TO “”，执行 RESET MASTER，这时候清空了master.info，再执行SHOW MASTER STATUS记录二进制坐标
* 比较其余备库与新主库的二进制坐标
* 将备库连接到新主库，并且执行CHANGE MASTER TO“新的二进制坐标”，指向新的主库。

### 期望的日志位置

* 如果备库的日志落后于新主库，则需要找到备库最后一条日志的位置，并找到其再新主库中对应的位置，并指向它，然后开始同步

### 主主服务器

* 停止主服务器的写入
* 设置主服务器只读，kill事务，
* 主动服务器上使用SHOW MASTER STATUS得到二进制坐标
* 再被动服务器上让二进制日志追赶。
* 关闭被动服务器的只读
* 修改配置

### 意外：

* 主库意外关闭：如果没有设置sync binlog，可能没有把二进制日志事件刷到磁盘，从而丢失
* 备库意外关闭：首先找到master.info去找到同步坐标，innoDB可以观察错误日志
* 主库的二进制文件损坏：备库将无法回复损坏的日志和事务，可以新开辟一个二进制日志，或者找到损坏的结尾处
* 备库的relay log错误：丢弃当前的中继日志，从损坏的地方重新使用CHANGE MASTER To
* 二进制日志和innoDB的事务日志不一致，当一个事务已经被标记为提交，但是事务日志没写进去，这个问题可防不可救

### 使用事务性和非事务性表

* 假如是事务表，进行改动会写到binlog，发生回滚的话，是不会刷新到二进制日志的。
* 如果使用两种混合，发生了一次回滚，事务表的更新被回滚了，但是非事务表没有，这时候mysql会查询并记录一天rollback到日志，让非事务表进行执行。

### 半同步复制：

* 在提交过程中增加一个延迟，提交事务是，在客户端接收到返回结果之前，可以保证数据已经复制到至少一台备库上。在等待的过程中，事务其实已经完成。只有客户端通知被延迟了，备库接收到事务就发送反馈，而非完成事务，如果超时，则会转化为正常的异步复制。
* 再关闭sync bin log时，可以使用这个来保证安全。

## 扩展MYSQL

### 数据分片：

* 对于重要而且频繁查找的数据减少分片，分区键决定每一行应该分到哪一个分片之中。
* 跨分片查询可以使用汇总表进行，避免了去每一个分区扫描
* 应该设计一个抽象层，负责：
  * 连接正确的分片并查询
  * 分布式一致性校验
  * 跨分片结果聚合
  * 跨分片关联
  * 锁和事务管理
  * 创建新的分片

### 负载均衡：

在服务器前端设置一个负载均衡器，负载均衡器负责将请求的连接路由到最空闲的服务器

目的：

* 可扩展性：读写分离时从备库读出数据
* 高效性：把更多读请求分给功能更强的服务器
* 保持可用性
* 透明性，客户端只需要和虚拟的负载均衡器通信
* 一致性：如果会话有状态，那么应该将同一个查询指向同一个服务器

## 直接连接的问题

### 复制上的读写分离

* 复制产生了多个副本，如何处理备库上的脏数据？将备库设置为只读，将主库设置为读写。对于不关心数据是否为脏数据的，让他请求备库，如果很在意消息的时效性，就请求主库。
* 比较常见的读写分离：
  * 基于查询分离：对于不关心数据是否为脏数据的，让他请求备库，如果很在意消息的时效性，就请求主库。
  * 基于脏数据分离：让应用检查复制延迟
  * 基于绘画分离：判读用户是否修改数据，用户不需要看到其他用户的数据更新，而是看到自己的更新，在会话层设置一个标记位，表明做了更新，短时间内该用户的请求都走主库
  * 基于版本分离：

### 引入中间件做负载均衡

#### 负载均衡器的特点：

* 需要保持一个有状态的会话固定到一个服务器以保护在Web服务器的会话状态
* 连接池和长连接可能会影响负载均衡器

#### 负载均衡算法：

* 随机
* 循环
* 最少连接数
* 最快响应
* 哈希
* 权重

# 高可用性：

### 服务器宕机的原因：

* 磁盘耗尽
* 写的很差的SQL语句
* 糟糕的SCHEMA 和索引
* 主备不一致的复制问题
* 没有备用数据导致的数据丢失

## 缓存

关键是要使用正确的缓存粒度和缓存过期策略

### 缓存总是有用吗？

不是的，缓存自身也有很多开销，检查、失效、写入新的缓存都有开销。

### 缓存控制策略：

* TTL过期时间
* 显式失效：不能接受脏数据，在写入时，使缓存中对应的数据失效或者更新
* 读失效：再更改数据的时候，在缓存中保留一些信息，来指明某条缓存已经被缓存中的数据已经失效。这样可以把巨额的失效操作慢慢完成，而不占用资源
  * 一种读失效方法：对象版本控制：在缓存中存储一个对象时，也存储相对的版本号。更新时标记版本过期

### 对缓存对象分层

不需要一次性把所有列都缓存进来，而是先缓存某几个列，在基于这几个列对其他列进行缓存。

# 备份方案

### 备份的总思路：

* 物理备份是必须的，逻辑备份太慢，而且受到资源限制。
* 要保留多个备份集
* 定期进行恢复测试
* 保存binlog方便进行数据恢复

### 在线备份还是离线备份？

* 离线备份风险最小，因为不用考虑刷新内存池中的脏页，还有未提交的事务
* 但是关闭和重启MYSQL服务器都是开销很大的，
* 备份会使用FLUSH TABLE WITH READ LOCK，这会导致关闭并锁住所有的表，将MYSIAM文件刷新到磁盘，然后刷新查询缓存。
* 使用InnoDB表，就不需要使用FLUSH TABLE WITH READ LOCK
* 要考虑的因素有：
  * 锁时间
  * 备份时间
  * 备份负载
  * 恢复时间

### 逻辑备份还是物理备份

#### 逻辑备份：

* 使用另外一台不同的服务器进行
* 可以使用where子句限制备份哪些行
* 与存储引擎无关
* 避免故障，有时候当磁盘数据损坏，而碰巧缓存中还有，则可以利用缓存的数据进行备份
* 占用更多CPU
* 有时产生的文件比源文件还要大，ASCII存储比普通存储要大很多
* 无法保证还原，比如浮点数
* 还原过程需要MYSQL加载和解释语句，需要很多时间

#### 物理备份

* 基于文件，直接复制
* 恢复简单，直接复制
* 容易跨平台
* 恢复更快
* 原始文件比逻辑备份大

#### 数据一致性：

* 对于非事务引擎，在备份时要锁表，对于InnoDB可以使用MVCC进行。

#### 文件一致性

* 对于非事务引擎，需要缩表并刷新缓存。使用FLUSH TABLE WITH READ LOCK ，刷新完成后，就可以安全的复制
* 对于InnoDB，即使使用FLUSH TABLE SITH READ LOCK也不行。

使用备库进行备份是最好的，可以避免主库出现额外的负载。

#### 备份二进制日志

日志格式：

* 第一行包含偏移字节值
* 第二行包含时间、服务器ID、下一时间的偏移字节值、事件类型、线程ID、执行时间与日志时间差，错误代码

设置expire log days可以设置自动清除老日志的参数

